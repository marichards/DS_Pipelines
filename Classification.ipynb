{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "In this notebook, I'll provide workflows for doing classification using the \"Iris\" dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "# General DS Libraries\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Pre-processing and Scoring\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
    "\n",
    "# Pre-processing and Scoring\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, train_test_split\n",
    "\n",
    "# Set up to use Latex\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the Iris dataset, loaded and with some info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal_length    150 non-null float64\n",
      "sepal_width     150 non-null float64\n",
      "petal_length    150 non-null float64\n",
      "petal_width     150 non-null float64\n",
      "species         150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.9+ KB\n",
      "None\n",
      "   sepal_length  sepal_width  petal_length  petal_width species\n",
      "0           5.1          3.5           1.4          0.2  setosa\n",
      "1           4.9          3.0           1.4          0.2  setosa\n",
      "2           4.7          3.2           1.3          0.2  setosa\n",
      "3           4.6          3.1           1.5          0.2  setosa\n",
      "4           5.0          3.6           1.4          0.2  setosa\n"
     ]
    }
   ],
   "source": [
    "# Load Iris dataset and print out info\n",
    "iris = sns.load_dataset('iris')\n",
    "print(iris.info())\n",
    "print(iris.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Some Simple Binary Classification\n",
    "\n",
    "Making a binary classification model, I can use lots of different strategies:\n",
    "\n",
    "* Logistic Regression\n",
    "* Naive Bayes\n",
    "* K-Nearest Neighbors\n",
    "* Simple Decision Tree\n",
    "* Random Forest\n",
    "* Gradient Boosting\n",
    "\n",
    "First, I'll just split up the data, using just virginica/versicolor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Setosa\n",
    "iris_binary = iris[iris.species != 'setosa']\n",
    "\n",
    "# Split X and Y\n",
    "X = iris_binary.drop(['species'], axis = 1, inplace=False)\n",
    "Y = iris_binary['species']\n",
    "\n",
    "# Split to train/test (80/20 split)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll make a predictAndROC function to make a prediction and make a ROC curve as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Multiclass Classification\n",
    "\n",
    "This is trickier because I now have to deal with all 3 classes. I'll have to re-make my train and test sets, but that's easy enough. More difficult is visualization; I'll do this using a heat map of the confusion matrix instead. \n",
    "\n",
    "### 1: Logistic Regression\n",
    "\n",
    "The issue here is that I have multiple classes; I'll get around that by using a OneVsRest approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier object\n",
    "lr = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
